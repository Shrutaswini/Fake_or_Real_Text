{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105874,"databundleVersionId":12964783,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ðŸ“Œ Introduction\n\nThis notebook presents my solution to the **\"Fake or Real: The Impostor Hunt\" Kaggle competition**. The task is to determine which of two edited texts is closer to the original. Subtle manipulationsâ€”syntactic or semanticâ€”are often made by LLMs, and our goal is to spot those patterns using a combination of interpretable and statistical NLP features.","metadata":{}},{"cell_type":"markdown","source":"## ðŸ” Problem Overview\n\nEach row in the dataset contains two texts (text_0 and text_1) that are variants of a source. We must predict which one is closer to the original. Evaluation is done using macro F1 score, making it important to handle class imbalance and edge cases.","metadata":{}},{"cell_type":"code","source":"!pip install textstat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:59:56.677019Z","iopub.execute_input":"2025-08-07T12:59:56.677599Z","iopub.status.idle":"2025-08-07T13:00:02.211737Z","shell.execute_reply.started":"2025-08-07T12:59:56.677570Z","shell.execute_reply":"2025-08-07T13:00:02.210831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:00:02.213586Z","iopub.execute_input":"2025-08-07T13:00:02.214029Z","iopub.status.idle":"2025-08-07T13:01:36.242505Z","shell.execute_reply.started":"2025-08-07T13:00:02.213975Z","shell.execute_reply":"2025-08-07T13:01:36.241323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport textstat\nimport spacy\nfrom textblob import TextBlob\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sentence_transformers import SentenceTransformer\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import cross_val_predict, RandomizedSearchCV\nfrom nltk.corpus import stopwords\nimport string\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nimport re\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:01:36.244001Z","iopub.execute_input":"2025-08-07T13:01:36.244327Z","iopub.status.idle":"2025-08-07T13:02:16.491311Z","shell.execute_reply.started":"2025-08-07T13:01:36.244281Z","shell.execute_reply":"2025-08-07T13:02:16.490391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.493115Z","iopub.execute_input":"2025-08-07T13:02:16.493837Z","iopub.status.idle":"2025-08-07T13:02:16.518251Z","shell.execute_reply.started":"2025-08-07T13:02:16.493791Z","shell.execute_reply":"2025-08-07T13:02:16.517224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.519308Z","iopub.execute_input":"2025-08-07T13:02:16.519625Z","iopub.status.idle":"2025-08-07T13:02:16.542895Z","shell.execute_reply.started":"2025-08-07T13:02:16.519596Z","shell.execute_reply":"2025-08-07T13:02:16.541950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_text_file(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.543920Z","iopub.execute_input":"2025-08-07T13:02:16.544836Z","iopub.status.idle":"2025-08-07T13:02:16.549300Z","shell.execute_reply.started":"2025-08-07T13:02:16.544805Z","shell.execute_reply":"2025-08-07T13:02:16.548401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/input/fake-or-real-the-impostor-hunt/data/train'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.550204Z","iopub.execute_input":"2025-08-07T13:02:16.550497Z","iopub.status.idle":"2025-08-07T13:02:16.567163Z","shell.execute_reply.started":"2025-08-07T13:02:16.550476Z","shell.execute_reply":"2025-08-07T13:02:16.566178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"texts = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.568276Z","iopub.execute_input":"2025-08-07T13:02:16.568755Z","iopub.status.idle":"2025-08-07T13:02:16.583927Z","shell.execute_reply.started":"2025-08-07T13:02:16.568724Z","shell.execute_reply":"2025-08-07T13:02:16.582968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for _, row in train_df.iterrows():\n    id_int = row['id']\n    id_str = f\"article_{id_int:04d}\"  \n    real_id = row['real_text_id']\n    \n    file1_path = os.path.join(train_dir, id_str, \"file_1.txt\")\n    file2_path = os.path.join(train_dir, id_str, \"file_2.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.585023Z","iopub.execute_input":"2025-08-07T13:02:16.585747Z","iopub.status.idle":"2025-08-07T13:02:16.606252Z","shell.execute_reply.started":"2025-08-07T13:02:16.585718Z","shell.execute_reply":"2025-08-07T13:02:16.605268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"  for idx, row in train_df.head(5).iterrows():\n    article_id = f\"article_{int(row['id']):04d}\"  # ensures format article_0000\n    base_path = f\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/{article_id}\"\n    \n    file1_path = os.path.join(base_path, 'file_1.txt')\n    file2_path = os.path.join(base_path, 'file_2.txt')\n\n    text1 = read_text_file(file1_path)\n    text2 = read_text_file(file2_path)\n\n    print(f\"Article ID: {row['id']}, Real file: file_{row['real_text_id']}.txt\")\n    print(\"---- FILE 1 ----\\n\", text1[:300], \"...\\n\")\n    print(\"---- FILE 2 ----\\n\", text2[:300], \"...\\n\")\n    print(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.609681Z","iopub.execute_input":"2025-08-07T13:02:16.610093Z","iopub.status.idle":"2025-08-07T13:02:16.688883Z","shell.execute_reply.started":"2025-08-07T13:02:16.610061Z","shell.execute_reply":"2025-08-07T13:02:16.688033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"   data = []\n\nfor idx, row in train_df.iterrows():\n    article_id = f\"article_{int(row['id']):04d}\"\n    base_path = f\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/{article_id}\"\n\n    file1_text = read_text_file(os.path.join(base_path, 'file_1.txt'))\n    file2_text = read_text_file(os.path.join(base_path, 'file_2.txt'))\n\n    data.append({\n        'id': row['id'],\n        'file_1': file1_text,\n        'file_2': file2_text,\n        'label': row['real_text_id']\n    })\n\ntrain_texts = pd.DataFrame(data)\ntrain_texts.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.689842Z","iopub.execute_input":"2025-08-07T13:02:16.690635Z","iopub.status.idle":"2025-08-07T13:02:17.672788Z","shell.execute_reply.started":"2025-08-07T13:02:16.690610Z","shell.execute_reply":"2025-08-07T13:02:17.671956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ› ï¸ Feature Engineering\n\nOur initial hypothesis: LLM-edited texts often diverge in subtle stylistic, syntactic, or semantic ways.\n\nWe engineered features across five domains:\n**Readability** : Flesch Reading Ease, Gunning Fog, SMOG\n**Lexical** : Word/Character counts, Average word length, TTR\n**Syntactic** : Noun/Verb/Adj counts via SpaCy\n**Sentiment** : Polarity & Subjectivity (TextBlob)\n\nOther linguistic cues: punctuation, entity repetition, speculative phrases, compression ratio","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\ntqdm.pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:17.673800Z","iopub.execute_input":"2025-08-07T13:02:17.674395Z","iopub.status.idle":"2025-08-07T13:02:18.683621Z","shell.execute_reply.started":"2025-08-07T13:02:17.674365Z","shell.execute_reply":"2025-08-07T13:02:18.682801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features(text):\n    blob = TextBlob(text)\n    doc = nlp(text)\n    return {\n        # Textstat readability\n        \"flesch\": textstat.flesch_reading_ease(text),\n        \"fog\": textstat.gunning_fog(text),\n        \"smog\": textstat.smog_index(text),\n        \"lexicon_count\": textstat.lexicon_count(text, removepunct=True),\n\n        # Lexical\n        \"word_count\": len(text.split()),\n        \"char_count\": len(text),\n        \"avg_word_len\": sum(len(w) for w in text.split()) / max(1, len(text.split())),\n        \"ttr\": len(set(text.split())) / max(1, len(text.split())),\n\n        # Syntactic\n        \"noun_count\": sum(1 for token in doc if token.pos_ == \"NOUN\"),\n        \"verb_count\": sum(1 for token in doc if token.pos_ == \"VERB\"),\n        \"adj_count\": sum(1 for token in doc if token.pos_ == \"ADJ\"),\n\n        # Sentiment\n        \"polarity\": blob.sentiment.polarity,\n        \"subjectivity\": blob.sentiment.subjectivity,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.684523Z","iopub.execute_input":"2025-08-07T13:02:18.684795Z","iopub.status.idle":"2025-08-07T13:02:18.691784Z","shell.execute_reply.started":"2025-08-07T13:02:18.684769Z","shell.execute_reply":"2025-08-07T13:02:18.690971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_texts.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.692735Z","iopub.execute_input":"2025-08-07T13:02:18.693090Z","iopub.status.idle":"2025-08-07T13:02:18.713537Z","shell.execute_reply.started":"2025-08-07T13:02:18.693045Z","shell.execute_reply":"2025-08-07T13:02:18.712630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_texts['features_1'] = train_texts['file_1'].progress_apply(extract_features)\ntrain_texts['features_2'] = train_texts['file_2'].progress_apply(extract_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.714661Z","iopub.execute_input":"2025-08-07T13:02:18.715512Z","iopub.status.idle":"2025-08-07T13:02:36.442409Z","shell.execute_reply.started":"2025-08-07T13:02:18.715481Z","shell.execute_reply":"2025-08-07T13:02:36.441469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_keys = list(train_texts['features_1'][0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.443425Z","iopub.execute_input":"2025-08-07T13:02:36.443761Z","iopub.status.idle":"2025-08-07T13:02:36.448408Z","shell.execute_reply.started":"2025-08-07T13:02:36.443731Z","shell.execute_reply":"2025-08-07T13:02:36.447451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dict_to_array(feature_dict):\n    return np.array([feature_dict[k] for k in feature_keys])\n\ntrain_texts['features_1_arr'] = train_texts['features_1'].apply(dict_to_array)\ntrain_texts['features_2_arr'] = train_texts['features_2'].apply(dict_to_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.449622Z","iopub.execute_input":"2025-08-07T13:02:36.450109Z","iopub.status.idle":"2025-08-07T13:02:36.510297Z","shell.execute_reply.started":"2025-08-07T13:02:36.450075Z","shell.execute_reply":"2025-08-07T13:02:36.509297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_delta(row):\n    return np.abs(row['features_1_arr'] - row['features_2_arr'])\n\ntrain_texts['delta_features'] = train_texts.apply(compute_delta, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.511318Z","iopub.execute_input":"2025-08-07T13:02:36.511767Z","iopub.status.idle":"2025-08-07T13:02:36.531365Z","shell.execute_reply.started":"2025-08-07T13:02:36.511734Z","shell.execute_reply":"2025-08-07T13:02:36.530263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ§ª Modeling Attempts\n\nWe tried several models with varying levels of feature complexity:\n\n| Model                        | Description                                                                          | Macro F1 |\n|-----------------------------|--------------------------------------------------------------------------------------|----------|\n| Random Forest               | Baseline using readability, lexical, syntactic, and sentiment features              | 0.53     |\n| XGBoost                     | Same features, better optimization                                                   | 0.63     |\n| SentenceTransformer + XGBoost | Added sentence embeddings to features                                            | 0.53     |\n| âœ… Final XGBoost            | Expanded feature set including speculative cues, stopword ratios, compression ratios, etc. | 0.75     |\n","metadata":{}},{"cell_type":"code","source":"X = list(train_texts['delta_features'])\ny = train_texts['label']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\n\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.532444Z","iopub.execute_input":"2025-08-07T13:02:36.533201Z","iopub.status.idle":"2025-08-07T13:02:36.710870Z","shell.execute_reply.started":"2025-08-07T13:02:36.533169Z","shell.execute_reply":"2025-08-07T13:02:36.709804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_texts['label'] = train_texts['label'].map({1: 0, 2: 1})\n\nX = np.vstack(train_texts['delta_features'].values)\ny = train_texts['label'].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=5,\n    learning_rate=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss',\n    random_state=42\n)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.712081Z","iopub.execute_input":"2025-08-07T13:02:36.712405Z","iopub.status.idle":"2025-08-07T13:02:36.831029Z","shell.execute_reply.started":"2025-08-07T13:02:36.712378Z","shell.execute_reply":"2025-08-07T13:02:36.830272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\n\nemb_1 = model.encode(train_texts['file_1'].tolist(), show_progress_bar=True)\nemb_2 = model.encode(train_texts['file_2'].tolist(), show_progress_bar=True)\n\nX = np.concatenate([emb_1, emb_2], axis=1)\ny = train_texts['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.831890Z","iopub.execute_input":"2025-08-07T13:02:36.832159Z","iopub.status.idle":"2025-08-07T13:02:58.128519Z","shell.execute_reply.started":"2025-08-07T13:02:36.832139Z","shell.execute_reply":"2025-08-07T13:02:58.127751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.129412Z","iopub.execute_input":"2025-08-07T13:02:58.129644Z","iopub.status.idle":"2025-08-07T13:02:58.297529Z","shell.execute_reply.started":"2025-08-07T13:02:58.129627Z","shell.execute_reply":"2025-08-07T13:02:58.296662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nnlp = spacy.load('en_core_web_sm')\nspeculative_words = {\"may\", \"might\", \"could\", \"probably\", \"possibly\", \"seems\", \"appears\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.298507Z","iopub.execute_input":"2025-08-07T13:02:58.298759Z","iopub.status.idle":"2025-08-07T13:02:58.937446Z","shell.execute_reply.started":"2025-08-07T13:02:58.298740Z","shell.execute_reply":"2025-08-07T13:02:58.936568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_classical_features(text):\n    doc = nlp(text)\n    tokens = [token.text.lower() for token in doc if token.is_alpha]\n    words = [token.text for token in doc if not token.is_punct]\n    tokens_count = len(words)\n    unique_tokens_count = len(set(words))\n    type_token_ratio = unique_tokens_count / tokens_count if tokens_count > 0 else 0\n    stopword_count = sum(1 for w in words if w.lower() in stop_words)\n    avg_word_len = sum(len(w) for w in words) / tokens_count if tokens_count > 0 else 0\n    punct_count = sum(1 for c in text if c in string.punctuation)\n    numeric_count = sum(1 for token in doc if token.like_num)\n    noun_ratio = len([token for token in doc if token.pos_ == 'NOUN']) / tokens_count if tokens_count > 0 else 0\n    verb_ratio = len([token for token in doc if token.pos_ == 'VERB']) / tokens_count if tokens_count > 0 else 0\n    adj_ratio = len([token for token in doc if token.pos_ == 'ADJ']) / tokens_count if tokens_count > 0 else 0\n    readability = textstat.flesch_reading_ease(text)\n    if len(set(tokens)) == 0:\n        comp_ratio = 0\n    else:\n        comp_ratio = len(tokens) / len(set(tokens))\n    speculative_count = sum(1 for token in tokens if token in speculative_words)\n    ents = [ent.text.lower() for ent in doc.ents]\n    ent_counts = Counter(ents)\n    if len(ents) == 0:\n        ent_repetition = 0\n    else:\n        repeated_ents = [ent for ent, count in ent_counts.items() if count > 1]\n        ent_repetition = len(repeated_ents) / len(ents)\n\n\n    return {\n        'tokens_count': tokens_count,\n        'type_token_ratio': type_token_ratio,\n        'stopword_count': stopword_count,\n        'avg_word_len': avg_word_len,\n        'punct_count': punct_count,\n        'numeric_count': numeric_count,\n        'noun_ratio': noun_ratio,\n        'verb_ratio': verb_ratio,\n        'adj_ratio': adj_ratio,\n        \"readability\": readability,\n        \"compression_ratio\": comp_ratio,\n        \"speculative_count\": speculative_count,\n        \"ent_repetition_ratio\": ent_repetition\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.938400Z","iopub.execute_input":"2025-08-07T13:02:58.938715Z","iopub.status.idle":"2025-08-07T13:02:58.949206Z","shell.execute_reply.started":"2025-08-07T13:02:58.938689Z","shell.execute_reply":"2025-08-07T13:02:58.948353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_features(train_texts):\n    features_1 = train_texts['file_1'].apply(extract_classical_features).apply(pd.Series)\n    features_2 = train_texts['file_2'].apply(extract_classical_features).apply(pd.Series)\n\n    \n    delta = (features_1 - features_2).abs().add_suffix('_delta')\n\n    \n    combined = pd.concat([\n        features_1.add_suffix('_1'),\n        features_2.add_suffix('_2'),\n        delta\n    ], axis=1)\n    \n    return combined\n\nX_features = add_features(train_texts)\ny = train_texts['label'].apply(lambda x: 0 if x == 1 else 1) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.950105Z","iopub.execute_input":"2025-08-07T13:02:58.950387Z","iopub.status.idle":"2025-08-07T13:03:13.183177Z","shell.execute_reply.started":"2025-08-07T13:02:58.950361Z","shell.execute_reply":"2025-08-07T13:03:13.182380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n\nparam_dist = {\n    'n_estimators': [50, 100, 200, 400],\n    'max_depth': [3, 5, 7, 10],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'reg_alpha': [0, 0.01, 0.1, 1],\n    'reg_lambda': [1, 1.5, 2, 3]\n}\n\nsearch = RandomizedSearchCV(\n    xgb, param_distributions=param_dist, n_iter=30,\n    scoring='f1_macro', cv=5, verbose=2, random_state=42, n_jobs=-1\n)\n\nsearch.fit(X_features, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:13.184086Z","iopub.execute_input":"2025-08-07T13:03:13.184362Z","iopub.status.idle":"2025-08-07T13:03:21.456049Z","shell.execute_reply.started":"2025-08-07T13:03:13.184334Z","shell.execute_reply":"2025-08-07T13:03:21.455153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = search.best_estimator_\n\ny_pred = cross_val_predict(best_model, X_features, y, cv=5)\nprint(\"Best parameters:\", search.best_params_)\nprint(\"\\nClassification report:\")\nprint(classification_report(y, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:21.457130Z","iopub.execute_input":"2025-08-07T13:03:21.457449Z","iopub.status.idle":"2025-08-07T13:03:21.840387Z","shell.execute_reply.started":"2025-08-07T13:03:21.457420Z","shell.execute_reply":"2025-08-07T13:03:21.839497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ”¢ Feature Importance\n\nWe visualized the top 15 features contributing to the modelâ€™s decision-making, revealing: \n**token count, punctuation count, compression ratio, and adjective count** among the top signals.","metadata":{}},{"cell_type":"code","source":"importances = best_model.feature_importances_\nfeat_names = X_features.columns\nsorted_idx = np.argsort(importances)[-15:]\n\nplt.figure(figsize=(10, 6))\nplt.barh(range(len(sorted_idx)), importances[sorted_idx])\nplt.yticks(range(len(sorted_idx)), [feat_names[i] for i in sorted_idx])\nplt.xlabel(\"Feature Importance\")\nplt.title(\"Top 15 Important Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:21.844853Z","iopub.execute_input":"2025-08-07T13:03:21.845347Z","iopub.status.idle":"2025-08-07T13:03:22.169649Z","shell.execute_reply.started":"2025-08-07T13:03:21.845324Z","shell.execute_reply":"2025-08-07T13:03:22.168714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ§¾ Test Predictions & Submission\nWe applied the final XGBoost model to the test set using the same preprocessing and feature pipeline. Predictions were formatted and exported as submission.csv.","metadata":{}},{"cell_type":"code","source":"test_dir = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:22.170507Z","iopub.execute_input":"2025-08-07T13:03:22.170739Z","iopub.status.idle":"2025-08-07T13:03:22.174887Z","shell.execute_reply.started":"2025-08-07T13:03:22.170714Z","shell.execute_reply":"2025-08-07T13:03:22.174038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\nsubdirs = sorted(os.listdir(test_dir))\n\nfor sub in subdirs:\n    sub_path = os.path.join(test_dir, sub)\n    if os.path.isdir(sub_path):\n        file1_path = os.path.join(sub_path, \"file_1.txt\")\n        file2_path = os.path.join(sub_path, \"file_2.txt\")\n        with open(file1_path, 'r', encoding='utf-8') as f:\n            text1 = f.read()\n        with open(file2_path, 'r', encoding='utf-8') as f:\n            text2 = f.read()\n        test_data.append({\n            \"id\": int(sub.replace(\"article_\", \"\")),\n            \"real_text_1\": text1,\n            \"real_text_2\": text2,\n            \"file1_path\": file1_path,\n            \"file2_path\": file2_path\n        })\n\ntest_df = pd.DataFrame(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:22.175717Z","iopub.execute_input":"2025-08-07T13:03:22.175975Z","iopub.status.idle":"2025-08-07T13:03:37.732413Z","shell.execute_reply.started":"2025-08-07T13:03:22.175949Z","shell.execute_reply":"2025-08-07T13:03:37.731288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:37.733714Z","iopub.execute_input":"2025-08-07T13:03:37.734094Z","iopub.status.idle":"2025-08-07T13:03:37.745076Z","shell.execute_reply.started":"2025-08-07T13:03:37.734064Z","shell.execute_reply":"2025-08-07T13:03:37.743866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:37.746266Z","iopub.execute_input":"2025-08-07T13:03:37.747208Z","iopub.status.idle":"2025-08-07T13:03:38.383532Z","shell.execute_reply.started":"2025-08-07T13:03:37.747177Z","shell.execute_reply":"2025-08-07T13:03:38.382566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_classical_features(text):\n    doc = nlp(text)\n    tokens = [token.text.lower() for token in doc if token.is_alpha]\n    words = [token.text for token in doc if not token.is_punct]\n    tokens_count = len(words)\n    unique_tokens_count = len(set(words))\n    type_token_ratio = unique_tokens_count / tokens_count if tokens_count > 0 else 0\n    stopword_count = sum(1 for w in words if w.lower() in stop_words)\n    avg_word_len = sum(len(w) for w in words) / tokens_count if tokens_count > 0 else 0\n    punct_count = sum(1 for c in text if c in string.punctuation)\n    numeric_count = sum(1 for token in doc if token.like_num)\n    noun_ratio = len([token for token in doc if token.pos_ == 'NOUN']) / tokens_count if tokens_count > 0 else 0\n    verb_ratio = len([token for token in doc if token.pos_ == 'VERB']) / tokens_count if tokens_count > 0 else 0\n    adj_ratio = len([token for token in doc if token.pos_ == 'ADJ']) / tokens_count if tokens_count > 0 else 0\n    readability = textstat.flesch_reading_ease(text)\n    if len(set(tokens)) == 0:\n        comp_ratio = 0\n    else:\n        comp_ratio = len(tokens) / len(set(tokens))\n    speculative_count = sum(1 for token in tokens if token in speculative_words)\n    ents = [ent.text.lower() for ent in doc.ents]\n    ent_counts = Counter(ents)\n    if len(ents) == 0:\n        ent_repetition = 0\n    else:\n        repeated_ents = [ent for ent, count in ent_counts.items() if count > 1]\n        ent_repetition = len(repeated_ents) / len(ents)\n\n    return {\n        'tokens_count': tokens_count,\n        'type_token_ratio': type_token_ratio,\n        'stopword_count': stopword_count,\n        'avg_word_len': avg_word_len,\n        'punct_count': punct_count,\n        'numeric_count': numeric_count,\n        'noun_ratio': noun_ratio,\n        'verb_ratio': verb_ratio,\n        'adj_ratio': adj_ratio,\n        \"readability\": readability,\n        \"compression_ratio\": comp_ratio,\n        \"speculative_count\": speculative_count,\n        \"ent_repetition_ratio\": ent_repetition\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:38.384485Z","iopub.execute_input":"2025-08-07T13:03:38.384785Z","iopub.status.idle":"2025-08-07T13:03:38.398130Z","shell.execute_reply.started":"2025-08-07T13:03:38.384754Z","shell.execute_reply":"2025-08-07T13:03:38.397281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_1 = []\nfeatures_2 = []\n\nfor _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    features_1.append(extract_classical_features(row[\"real_text_1\"]))\n    features_2.append(extract_classical_features(row[\"real_text_2\"]))\n\nfeatures_df_1 = pd.DataFrame(features_1)\nfeatures_df_2 = pd.DataFrame(features_2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:38.399235Z","iopub.execute_input":"2025-08-07T13:03:38.399663Z","iopub.status.idle":"2025-08-07T13:05:54.421268Z","shell.execute_reply.started":"2025-08-07T13:03:38.399639Z","shell.execute_reply":"2025-08-07T13:05:54.420295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_df_1.columns = [f\"{col}_1\" for col in features_df_1.columns]\nfeatures_df_2.columns = [f\"{col}_2\" for col in features_df_2.columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:05:54.422354Z","iopub.execute_input":"2025-08-07T13:05:54.422621Z","iopub.status.idle":"2025-08-07T13:05:54.427501Z","shell.execute_reply.started":"2025-08-07T13:05:54.422600Z","shell.execute_reply":"2025-08-07T13:05:54.426824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_features = pd.concat([features_df_1, features_df_2], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:05:54.428423Z","iopub.execute_input":"2025-08-07T13:05:54.428725Z","iopub.status.idle":"2025-08-07T13:05:54.448060Z","shell.execute_reply.started":"2025-08-07T13:05:54.428700Z","shell.execute_reply":"2025-08-07T13:05:54.447300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"delta_features = features_df_1.values - features_df_2.values\n\ndelta_df = pd.DataFrame(\n    delta_features,\n    columns=[f\"{col.replace('_1', '')}_delta\" for col in features_df_1.columns]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:23.508601Z","iopub.execute_input":"2025-08-07T13:08:23.509700Z","iopub.status.idle":"2025-08-07T13:08:23.516874Z","shell.execute_reply.started":"2025-08-07T13:08:23.509668Z","shell.execute_reply":"2025-08-07T13:08:23.515946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = pd.concat([features_df_1, features_df_2, delta_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:27.590091Z","iopub.execute_input":"2025-08-07T13:08:27.590414Z","iopub.status.idle":"2025-08-07T13:08:27.596820Z","shell.execute_reply.started":"2025-08-07T13:08:27.590393Z","shell.execute_reply":"2025-08-07T13:08:27.596035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_preds = search.best_estimator_.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:29.574585Z","iopub.execute_input":"2025-08-07T13:08:29.574929Z","iopub.status.idle":"2025-08-07T13:08:29.588789Z","shell.execute_reply.started":"2025-08-07T13:08:29.574906Z","shell.execute_reply":"2025-08-07T13:08:29.587858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_preds = test_preds + 1\n\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"real_text_file\": submission_preds.astype(int)\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:31.209970Z","iopub.execute_input":"2025-08-07T13:08:31.210935Z","iopub.status.idle":"2025-08-07T13:08:31.216646Z","shell.execute_reply.started":"2025-08-07T13:08:31.210905Z","shell.execute_reply":"2025-08-07T13:08:31.215742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.sort_values(\"id\", inplace=True)\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"âœ… Submission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:35.895226Z","iopub.execute_input":"2025-08-07T13:08:35.895938Z","iopub.status.idle":"2025-08-07T13:08:35.911450Z","shell.execute_reply.started":"2025-08-07T13:08:35.895911Z","shell.execute_reply":"2025-08-07T13:08:35.910357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## âœ… Summary & Learnings\nInterpretable linguistic features consistently outperformed black-box embeddings.\n\nCombining readability and compression measures proved powerful for catching subtle LLM edits.\n\nEnsemble models did not improve performance significantly, suggesting handcrafted features already captured key discriminative signals.\n\n","metadata":{}}]}