{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105874,"databundleVersionId":12964783,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## üìå Introduction\n\nThis notebook presents my solution to the **\"Fake or Real: The Impostor Hunt\" Kaggle competition**. The task is to determine which of two edited texts is closer to the original. Subtle manipulations‚Äîsyntactic or semantic‚Äîare often made by LLMs, and our goal is to spot those patterns using a combination of interpretable and statistical NLP features.","metadata":{}},{"cell_type":"markdown","source":"## üîç Problem Overview\n\nEach row in the dataset contains two texts (text_0 and text_1) that are variants of a source. We must predict which one is closer to the original. Evaluation is done using macro F1 score, making it important to handle class imbalance and edge cases.","metadata":{}},{"cell_type":"code","source":"!pip install textstat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:59:56.677019Z","iopub.execute_input":"2025-08-07T12:59:56.677599Z","iopub.status.idle":"2025-08-07T13:00:02.211737Z","shell.execute_reply.started":"2025-08-07T12:59:56.677570Z","shell.execute_reply":"2025-08-07T13:00:02.210831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:00:02.213586Z","iopub.execute_input":"2025-08-07T13:00:02.214029Z","iopub.status.idle":"2025-08-07T13:01:36.242505Z","shell.execute_reply.started":"2025-08-07T13:00:02.213975Z","shell.execute_reply":"2025-08-07T13:01:36.241323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport textstat\nimport spacy\nfrom textblob import TextBlob\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sentence_transformers import SentenceTransformer\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import cross_val_predict, RandomizedSearchCV\nfrom nltk.corpus import stopwords\nimport string\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nimport re\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:01:36.244001Z","iopub.execute_input":"2025-08-07T13:01:36.244327Z","iopub.status.idle":"2025-08-07T13:02:16.491311Z","shell.execute_reply.started":"2025-08-07T13:01:36.244281Z","shell.execute_reply":"2025-08-07T13:02:16.490391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.493115Z","iopub.execute_input":"2025-08-07T13:02:16.493837Z","iopub.status.idle":"2025-08-07T13:02:16.518251Z","shell.execute_reply.started":"2025-08-07T13:02:16.493791Z","shell.execute_reply":"2025-08-07T13:02:16.517224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.519308Z","iopub.execute_input":"2025-08-07T13:02:16.519625Z","iopub.status.idle":"2025-08-07T13:02:16.542895Z","shell.execute_reply.started":"2025-08-07T13:02:16.519596Z","shell.execute_reply":"2025-08-07T13:02:16.541950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_text_file(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.543920Z","iopub.execute_input":"2025-08-07T13:02:16.544836Z","iopub.status.idle":"2025-08-07T13:02:16.549300Z","shell.execute_reply.started":"2025-08-07T13:02:16.544805Z","shell.execute_reply":"2025-08-07T13:02:16.548401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/input/fake-or-real-the-impostor-hunt/data/train'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.550204Z","iopub.execute_input":"2025-08-07T13:02:16.550497Z","iopub.status.idle":"2025-08-07T13:02:16.567163Z","shell.execute_reply.started":"2025-08-07T13:02:16.550476Z","shell.execute_reply":"2025-08-07T13:02:16.566178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"texts = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.568276Z","iopub.execute_input":"2025-08-07T13:02:16.568755Z","iopub.status.idle":"2025-08-07T13:02:16.583927Z","shell.execute_reply.started":"2025-08-07T13:02:16.568724Z","shell.execute_reply":"2025-08-07T13:02:16.582968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for _, row in train_df.iterrows():\n    id_int = row['id']\n    id_str = f\"article_{id_int:04d}\"  \n    real_id = row['real_text_id']\n    \n    file1_path = os.path.join(train_dir, id_str, \"file_1.txt\")\n    file2_path = os.path.join(train_dir, id_str, \"file_2.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.585023Z","iopub.execute_input":"2025-08-07T13:02:16.585747Z","iopub.status.idle":"2025-08-07T13:02:16.606252Z","shell.execute_reply.started":"2025-08-07T13:02:16.585718Z","shell.execute_reply":"2025-08-07T13:02:16.605268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"  for idx, row in train_df.head(5).iterrows():\n    article_id = f\"article_{int(row['id']):04d}\"  # ensures format article_0000\n    base_path = f\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/{article_id}\"\n    \n    file1_path = os.path.join(base_path, 'file_1.txt')\n    file2_path = os.path.join(base_path, 'file_2.txt')\n\n    text1 = read_text_file(file1_path)\n    text2 = read_text_file(file2_path)\n\n    print(f\"Article ID: {row['id']}, Real file: file_{row['real_text_id']}.txt\")\n    print(\"---- FILE 1 ----\\n\", text1[:300], \"...\\n\")\n    print(\"---- FILE 2 ----\\n\", text2[:300], \"...\\n\")\n    print(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.609681Z","iopub.execute_input":"2025-08-07T13:02:16.610093Z","iopub.status.idle":"2025-08-07T13:02:16.688883Z","shell.execute_reply.started":"2025-08-07T13:02:16.610061Z","shell.execute_reply":"2025-08-07T13:02:16.688033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"   data = []\n\nfor idx, row in train_df.iterrows():\n    article_id = f\"article_{int(row['id']):04d}\"\n    base_path = f\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/{article_id}\"\n\n    file1_text = read_text_file(os.path.join(base_path, 'file_1.txt'))\n    file2_text = read_text_file(os.path.join(base_path, 'file_2.txt'))\n\n    data.append({\n        'id': row['id'],\n        'file_1': file1_text,\n        'file_2': file2_text,\n        'label': row['real_text_id']\n    })\n\ntrain_texts = pd.DataFrame(data)\ntrain_texts.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:16.689842Z","iopub.execute_input":"2025-08-07T13:02:16.690635Z","iopub.status.idle":"2025-08-07T13:02:17.672788Z","shell.execute_reply.started":"2025-08-07T13:02:16.690610Z","shell.execute_reply":"2025-08-07T13:02:17.671956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üõ†Ô∏è Feature Engineering\n\nOur initial hypothesis: LLM-edited texts often diverge in subtle stylistic, syntactic, or semantic ways.\n\nWe engineered features across five domains:\n**Readability** : Flesch Reading Ease, Gunning Fog, SMOG\n**Lexical** : Word/Character counts, Average word length, TTR\n**Syntactic** : Noun/Verb/Adj counts via SpaCy\n**Sentiment** : Polarity & Subjectivity (TextBlob)\n\nOther linguistic cues: punctuation, entity repetition, speculative phrases, compression ratio","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\ntqdm.pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:17.673800Z","iopub.execute_input":"2025-08-07T13:02:17.674395Z","iopub.status.idle":"2025-08-07T13:02:18.683621Z","shell.execute_reply.started":"2025-08-07T13:02:17.674365Z","shell.execute_reply":"2025-08-07T13:02:18.682801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features(text):\n    blob = TextBlob(text)\n    doc = nlp(text)\n    return {\n        # Textstat readability\n        \"flesch\": textstat.flesch_reading_ease(text),\n        \"fog\": textstat.gunning_fog(text),\n        \"smog\": textstat.smog_index(text),\n        \"lexicon_count\": textstat.lexicon_count(text, removepunct=True),\n\n        # Lexical\n        \"word_count\": len(text.split()),\n        \"char_count\": len(text),\n        \"avg_word_len\": sum(len(w) for w in text.split()) / max(1, len(text.split())),\n        \"ttr\": len(set(text.split())) / max(1, len(text.split())),\n\n        # Syntactic\n        \"noun_count\": sum(1 for token in doc if token.pos_ == \"NOUN\"),\n        \"verb_count\": sum(1 for token in doc if token.pos_ == \"VERB\"),\n        \"adj_count\": sum(1 for token in doc if token.pos_ == \"ADJ\"),\n\n        # Sentiment\n        \"polarity\": blob.sentiment.polarity,\n        \"subjectivity\": blob.sentiment.subjectivity,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.684523Z","iopub.execute_input":"2025-08-07T13:02:18.684795Z","iopub.status.idle":"2025-08-07T13:02:18.691784Z","shell.execute_reply.started":"2025-08-07T13:02:18.684769Z","shell.execute_reply":"2025-08-07T13:02:18.690971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_texts.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.692735Z","iopub.execute_input":"2025-08-07T13:02:18.693090Z","iopub.status.idle":"2025-08-07T13:02:18.713537Z","shell.execute_reply.started":"2025-08-07T13:02:18.693045Z","shell.execute_reply":"2025-08-07T13:02:18.712630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_texts['features_1'] = train_texts['file_1'].progress_apply(extract_features)\ntrain_texts['features_2'] = train_texts['file_2'].progress_apply(extract_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:18.714661Z","iopub.execute_input":"2025-08-07T13:02:18.715512Z","iopub.status.idle":"2025-08-07T13:02:36.442409Z","shell.execute_reply.started":"2025-08-07T13:02:18.715481Z","shell.execute_reply":"2025-08-07T13:02:36.441469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_keys = list(train_texts['features_1'][0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.443425Z","iopub.execute_input":"2025-08-07T13:02:36.443761Z","iopub.status.idle":"2025-08-07T13:02:36.448408Z","shell.execute_reply.started":"2025-08-07T13:02:36.443731Z","shell.execute_reply":"2025-08-07T13:02:36.447451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dict_to_array(feature_dict):\n    return np.array([feature_dict[k] for k in feature_keys])\n\ntrain_texts['features_1_arr'] = train_texts['features_1'].apply(dict_to_array)\ntrain_texts['features_2_arr'] = train_texts['features_2'].apply(dict_to_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.449622Z","iopub.execute_input":"2025-08-07T13:02:36.450109Z","iopub.status.idle":"2025-08-07T13:02:36.510297Z","shell.execute_reply.started":"2025-08-07T13:02:36.450075Z","shell.execute_reply":"2025-08-07T13:02:36.509297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_delta(row):\n    return np.abs(row['features_1_arr'] - row['features_2_arr'])\n\ntrain_texts['delta_features'] = train_texts.apply(compute_delta, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.511318Z","iopub.execute_input":"2025-08-07T13:02:36.511767Z","iopub.status.idle":"2025-08-07T13:02:36.531365Z","shell.execute_reply.started":"2025-08-07T13:02:36.511734Z","shell.execute_reply":"2025-08-07T13:02:36.530263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß™ Modeling Attempts\n\nWe tried several models with varying levels of feature complexity:\n\n| Model                        | Description                                                                          | Macro F1 |\n|-----------------------------|--------------------------------------------------------------------------------------|----------|\n| Random Forest               | Baseline using readability, lexical, syntactic, and sentiment features              | 0.53     |\n| XGBoost                     | Same features, better optimization                                                   | 0.63     |\n| SentenceTransformer + XGBoost | Added sentence embeddings to features                                            | 0.53     |\n| ‚úÖ Final XGBoost            | Expanded feature set including speculative cues, stopword ratios, compression ratios, etc. | 0.75     |\n","metadata":{}},{"cell_type":"code","source":"X = list(train_texts['delta_features'])\ny = train_texts['label']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\n\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.532444Z","iopub.execute_input":"2025-08-07T13:02:36.533201Z","iopub.status.idle":"2025-08-07T13:02:36.710870Z","shell.execute_reply.started":"2025-08-07T13:02:36.533169Z","shell.execute_reply":"2025-08-07T13:02:36.709804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_texts['label'] = train_texts['label'].map({1: 0, 2: 1})\n\nX = np.vstack(train_texts['delta_features'].values)\ny = train_texts['label'].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = xgb.XGBClassifier(\n    n_estimators=200,\n    max_depth=5,\n    learning_rate=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss',\n    random_state=42\n)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.712081Z","iopub.execute_input":"2025-08-07T13:02:36.712405Z","iopub.status.idle":"2025-08-07T13:02:36.831029Z","shell.execute_reply.started":"2025-08-07T13:02:36.712378Z","shell.execute_reply":"2025-08-07T13:02:36.830272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\n\nemb_1 = model.encode(train_texts['file_1'].tolist(), show_progress_bar=True)\nemb_2 = model.encode(train_texts['file_2'].tolist(), show_progress_bar=True)\n\nX = np.concatenate([emb_1, emb_2], axis=1)\ny = train_texts['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:36.831890Z","iopub.execute_input":"2025-08-07T13:02:36.832159Z","iopub.status.idle":"2025-08-07T13:02:58.128519Z","shell.execute_reply.started":"2025-08-07T13:02:36.832139Z","shell.execute_reply":"2025-08-07T13:02:58.127751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.129412Z","iopub.execute_input":"2025-08-07T13:02:58.129644Z","iopub.status.idle":"2025-08-07T13:02:58.297529Z","shell.execute_reply.started":"2025-08-07T13:02:58.129627Z","shell.execute_reply":"2025-08-07T13:02:58.296662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nnlp = spacy.load('en_core_web_sm')\nspeculative_words = {\"may\", \"might\", \"could\", \"probably\", \"possibly\", \"seems\", \"appears\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.298507Z","iopub.execute_input":"2025-08-07T13:02:58.298759Z","iopub.status.idle":"2025-08-07T13:02:58.937446Z","shell.execute_reply.started":"2025-08-07T13:02:58.298740Z","shell.execute_reply":"2025-08-07T13:02:58.936568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_classical_features(text):\n    doc = nlp(text)\n    tokens = [token.text.lower() for token in doc if token.is_alpha]\n    words = [token.text for token in doc if not token.is_punct]\n    tokens_count = len(words)\n    unique_tokens_count = len(set(words))\n    type_token_ratio = unique_tokens_count / tokens_count if tokens_count > 0 else 0\n    stopword_count = sum(1 for w in words if w.lower() in stop_words)\n    avg_word_len = sum(len(w) for w in words) / tokens_count if tokens_count > 0 else 0\n    punct_count = sum(1 for c in text if c in string.punctuation)\n    numeric_count = sum(1 for token in doc if token.like_num)\n    noun_ratio = len([token for token in doc if token.pos_ == 'NOUN']) / tokens_count if tokens_count > 0 else 0\n    verb_ratio = len([token for token in doc if token.pos_ == 'VERB']) / tokens_count if tokens_count > 0 else 0\n    adj_ratio = len([token for token in doc if token.pos_ == 'ADJ']) / tokens_count if tokens_count > 0 else 0\n    readability = textstat.flesch_reading_ease(text)\n    if len(set(tokens)) == 0:\n        comp_ratio = 0\n    else:\n        comp_ratio = len(tokens) / len(set(tokens))\n    speculative_count = sum(1 for token in tokens if token in speculative_words)\n    ents = [ent.text.lower() for ent in doc.ents]\n    ent_counts = Counter(ents)\n    if len(ents) == 0:\n        ent_repetition = 0\n    else:\n        repeated_ents = [ent for ent, count in ent_counts.items() if count > 1]\n        ent_repetition = len(repeated_ents) / len(ents)\n\n\n    return {\n        'tokens_count': tokens_count,\n        'type_token_ratio': type_token_ratio,\n        'stopword_count': stopword_count,\n        'avg_word_len': avg_word_len,\n        'punct_count': punct_count,\n        'numeric_count': numeric_count,\n        'noun_ratio': noun_ratio,\n        'verb_ratio': verb_ratio,\n        'adj_ratio': adj_ratio,\n        \"readability\": readability,\n        \"compression_ratio\": comp_ratio,\n        \"speculative_count\": speculative_count,\n        \"ent_repetition_ratio\": ent_repetition\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.938400Z","iopub.execute_input":"2025-08-07T13:02:58.938715Z","iopub.status.idle":"2025-08-07T13:02:58.949206Z","shell.execute_reply.started":"2025-08-07T13:02:58.938689Z","shell.execute_reply":"2025-08-07T13:02:58.948353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_features(train_texts):\n    features_1 = train_texts['file_1'].apply(extract_classical_features).apply(pd.Series)\n    features_2 = train_texts['file_2'].apply(extract_classical_features).apply(pd.Series)\n\n    \n    delta = (features_1 - features_2).abs().add_suffix('_delta')\n\n    \n    combined = pd.concat([\n        features_1.add_suffix('_1'),\n        features_2.add_suffix('_2'),\n        delta\n    ], axis=1)\n    \n    return combined\n\nX_features = add_features(train_texts)\ny = train_texts['label'].apply(lambda x: 0 if x == 1 else 1) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:02:58.950105Z","iopub.execute_input":"2025-08-07T13:02:58.950387Z","iopub.status.idle":"2025-08-07T13:03:13.183177Z","shell.execute_reply.started":"2025-08-07T13:02:58.950361Z","shell.execute_reply":"2025-08-07T13:03:13.182380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n\nparam_dist = {\n    'n_estimators': [50, 100, 200, 400],\n    'max_depth': [3, 5, 7, 10],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'reg_alpha': [0, 0.01, 0.1, 1],\n    'reg_lambda': [1, 1.5, 2, 3]\n}\n\nsearch = RandomizedSearchCV(\n    xgb, param_distributions=param_dist, n_iter=30,\n    scoring='f1_macro', cv=5, verbose=2, random_state=42, n_jobs=-1\n)\n\nsearch.fit(X_features, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:13.184086Z","iopub.execute_input":"2025-08-07T13:03:13.184362Z","iopub.status.idle":"2025-08-07T13:03:21.456049Z","shell.execute_reply.started":"2025-08-07T13:03:13.184334Z","shell.execute_reply":"2025-08-07T13:03:21.455153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = search.best_estimator_\n\ny_pred = cross_val_predict(best_model, X_features, y, cv=5)\nprint(\"Best parameters:\", search.best_params_)\nprint(\"\\nClassification report:\")\nprint(classification_report(y, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:21.457130Z","iopub.execute_input":"2025-08-07T13:03:21.457449Z","iopub.status.idle":"2025-08-07T13:03:21.840387Z","shell.execute_reply.started":"2025-08-07T13:03:21.457420Z","shell.execute_reply":"2025-08-07T13:03:21.839497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üî¢ Feature Importance\n\nWe visualized the top 15 features contributing to the model‚Äôs decision-making, revealing: \n**token count, punctuation count, compression ratio, and adjective count** among the top signals.","metadata":{}},{"cell_type":"code","source":"importances = best_model.feature_importances_\nfeat_names = X_features.columns\nsorted_idx = np.argsort(importances)[-15:]\n\nplt.figure(figsize=(10, 6))\nplt.barh(range(len(sorted_idx)), importances[sorted_idx])\nplt.yticks(range(len(sorted_idx)), [feat_names[i] for i in sorted_idx])\nplt.xlabel(\"Feature Importance\")\nplt.title(\"Top 15 Important Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:21.844853Z","iopub.execute_input":"2025-08-07T13:03:21.845347Z","iopub.status.idle":"2025-08-07T13:03:22.169649Z","shell.execute_reply.started":"2025-08-07T13:03:21.845324Z","shell.execute_reply":"2025-08-07T13:03:22.168714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üßæ Test Predictions & Submission\nWe applied the final XGBoost model to the test set using the same preprocessing and feature pipeline. Predictions were formatted and exported as submission.csv.","metadata":{}},{"cell_type":"code","source":"test_dir = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:22.170507Z","iopub.execute_input":"2025-08-07T13:03:22.170739Z","iopub.status.idle":"2025-08-07T13:03:22.174887Z","shell.execute_reply.started":"2025-08-07T13:03:22.170714Z","shell.execute_reply":"2025-08-07T13:03:22.174038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\nsubdirs = sorted(os.listdir(test_dir))\n\nfor sub in subdirs:\n    sub_path = os.path.join(test_dir, sub)\n    if os.path.isdir(sub_path):\n        file1_path = os.path.join(sub_path, \"file_1.txt\")\n        file2_path = os.path.join(sub_path, \"file_2.txt\")\n        with open(file1_path, 'r', encoding='utf-8') as f:\n            text1 = f.read()\n        with open(file2_path, 'r', encoding='utf-8') as f:\n            text2 = f.read()\n        test_data.append({\n            \"id\": int(sub.replace(\"article_\", \"\")),\n            \"real_text_1\": text1,\n            \"real_text_2\": text2,\n            \"file1_path\": file1_path,\n            \"file2_path\": file2_path\n        })\n\ntest_df = pd.DataFrame(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:22.175717Z","iopub.execute_input":"2025-08-07T13:03:22.175975Z","iopub.status.idle":"2025-08-07T13:03:37.732413Z","shell.execute_reply.started":"2025-08-07T13:03:22.175949Z","shell.execute_reply":"2025-08-07T13:03:37.731288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:37.733714Z","iopub.execute_input":"2025-08-07T13:03:37.734094Z","iopub.status.idle":"2025-08-07T13:03:37.745076Z","shell.execute_reply.started":"2025-08-07T13:03:37.734064Z","shell.execute_reply":"2025-08-07T13:03:37.743866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:37.746266Z","iopub.execute_input":"2025-08-07T13:03:37.747208Z","iopub.status.idle":"2025-08-07T13:03:38.383532Z","shell.execute_reply.started":"2025-08-07T13:03:37.747177Z","shell.execute_reply":"2025-08-07T13:03:38.382566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_classical_features(text):\n    doc = nlp(text)\n    tokens = [token.text.lower() for token in doc if token.is_alpha]\n    words = [token.text for token in doc if not token.is_punct]\n    tokens_count = len(words)\n    unique_tokens_count = len(set(words))\n    type_token_ratio = unique_tokens_count / tokens_count if tokens_count > 0 else 0\n    stopword_count = sum(1 for w in words if w.lower() in stop_words)\n    avg_word_len = sum(len(w) for w in words) / tokens_count if tokens_count > 0 else 0\n    punct_count = sum(1 for c in text if c in string.punctuation)\n    numeric_count = sum(1 for token in doc if token.like_num)\n    noun_ratio = len([token for token in doc if token.pos_ == 'NOUN']) / tokens_count if tokens_count > 0 else 0\n    verb_ratio = len([token for token in doc if token.pos_ == 'VERB']) / tokens_count if tokens_count > 0 else 0\n    adj_ratio = len([token for token in doc if token.pos_ == 'ADJ']) / tokens_count if tokens_count > 0 else 0\n    readability = textstat.flesch_reading_ease(text)\n    if len(set(tokens)) == 0:\n        comp_ratio = 0\n    else:\n        comp_ratio = len(tokens) / len(set(tokens))\n    speculative_count = sum(1 for token in tokens if token in speculative_words)\n    ents = [ent.text.lower() for ent in doc.ents]\n    ent_counts = Counter(ents)\n    if len(ents) == 0:\n        ent_repetition = 0\n    else:\n        repeated_ents = [ent for ent, count in ent_counts.items() if count > 1]\n        ent_repetition = len(repeated_ents) / len(ents)\n\n    return {\n        'tokens_count': tokens_count,\n        'type_token_ratio': type_token_ratio,\n        'stopword_count': stopword_count,\n        'avg_word_len': avg_word_len,\n        'punct_count': punct_count,\n        'numeric_count': numeric_count,\n        'noun_ratio': noun_ratio,\n        'verb_ratio': verb_ratio,\n        'adj_ratio': adj_ratio,\n        \"readability\": readability,\n        \"compression_ratio\": comp_ratio,\n        \"speculative_count\": speculative_count,\n        \"ent_repetition_ratio\": ent_repetition\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:38.384485Z","iopub.execute_input":"2025-08-07T13:03:38.384785Z","iopub.status.idle":"2025-08-07T13:03:38.398130Z","shell.execute_reply.started":"2025-08-07T13:03:38.384754Z","shell.execute_reply":"2025-08-07T13:03:38.397281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_1 = []\nfeatures_2 = []\n\nfor _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    features_1.append(extract_classical_features(row[\"real_text_1\"]))\n    features_2.append(extract_classical_features(row[\"real_text_2\"]))\n\nfeatures_df_1 = pd.DataFrame(features_1)\nfeatures_df_2 = pd.DataFrame(features_2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:03:38.399235Z","iopub.execute_input":"2025-08-07T13:03:38.399663Z","iopub.status.idle":"2025-08-07T13:05:54.421268Z","shell.execute_reply.started":"2025-08-07T13:03:38.399639Z","shell.execute_reply":"2025-08-07T13:05:54.420295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_df_1.columns = [f\"{col}_1\" for col in features_df_1.columns]\nfeatures_df_2.columns = [f\"{col}_2\" for col in features_df_2.columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:05:54.422354Z","iopub.execute_input":"2025-08-07T13:05:54.422621Z","iopub.status.idle":"2025-08-07T13:05:54.427501Z","shell.execute_reply.started":"2025-08-07T13:05:54.422600Z","shell.execute_reply":"2025-08-07T13:05:54.426824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_features = pd.concat([features_df_1, features_df_2], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:05:54.428423Z","iopub.execute_input":"2025-08-07T13:05:54.428725Z","iopub.status.idle":"2025-08-07T13:05:54.448060Z","shell.execute_reply.started":"2025-08-07T13:05:54.428700Z","shell.execute_reply":"2025-08-07T13:05:54.447300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"delta_features = features_df_1.values - features_df_2.values\n\ndelta_df = pd.DataFrame(\n    delta_features,\n    columns=[f\"{col.replace('_1', '')}_delta\" for col in features_df_1.columns]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:23.508601Z","iopub.execute_input":"2025-08-07T13:08:23.509700Z","iopub.status.idle":"2025-08-07T13:08:23.516874Z","shell.execute_reply.started":"2025-08-07T13:08:23.509668Z","shell.execute_reply":"2025-08-07T13:08:23.515946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = pd.concat([features_df_1, features_df_2, delta_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:27.590091Z","iopub.execute_input":"2025-08-07T13:08:27.590414Z","iopub.status.idle":"2025-08-07T13:08:27.596820Z","shell.execute_reply.started":"2025-08-07T13:08:27.590393Z","shell.execute_reply":"2025-08-07T13:08:27.596035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_preds = search.best_estimator_.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:29.574585Z","iopub.execute_input":"2025-08-07T13:08:29.574929Z","iopub.status.idle":"2025-08-07T13:08:29.588789Z","shell.execute_reply.started":"2025-08-07T13:08:29.574906Z","shell.execute_reply":"2025-08-07T13:08:29.587858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_preds = test_preds + 1\n\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"real_text_file\": submission_preds.astype(int)\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:31.209970Z","iopub.execute_input":"2025-08-07T13:08:31.210935Z","iopub.status.idle":"2025-08-07T13:08:31.216646Z","shell.execute_reply.started":"2025-08-07T13:08:31.210905Z","shell.execute_reply":"2025-08-07T13:08:31.215742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.sort_values(\"id\", inplace=True)\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"‚úÖ Submission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T13:08:35.895226Z","iopub.execute_input":"2025-08-07T13:08:35.895938Z","iopub.status.idle":"2025-08-07T13:08:35.911450Z","shell.execute_reply.started":"2025-08-07T13:08:35.895911Z","shell.execute_reply":"2025-08-07T13:08:35.910357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚úÖ Summary & Learnings\nInterpretable linguistic features consistently outperformed black-box embeddings.\n\nCombining readability and compression measures proved powerful for catching subtle LLM edits.\n\nEnsemble models did not improve performance significantly, suggesting handcrafted features already captured key discriminative signals.\n\n","metadata":{}}]}